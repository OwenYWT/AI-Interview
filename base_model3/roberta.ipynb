{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de0f6bc305e56eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:07:20.173666Z",
     "start_time": "2024-12-01T00:07:20.144482Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "\n",
    "print(os.environ.get(\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae5f97a279d16d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:07:31.545718Z",
     "start_time": "2024-12-01T00:07:20.151730Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import yaml\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "\tRobertaTokenizerFast,\n",
    "\tRobertaForSequenceClassification,\n",
    "\tTrainingArguments,\n",
    "\tAutoConfig,\n",
    ")\n",
    "from dataset import HierarchicalInterviewDataset\n",
    "import pandas as pd\n",
    "\n",
    "from model import HierarchicalInterviewScorer\n",
    "from trainer import Trainer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model_utils import tokenize_dialogue, predict_scores, format_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77c191d30afc47c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:07:32.465995Z",
     "start_time": "2024-12-01T00:07:32.438758Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available.\n",
      "mps is available!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\tprint(\"GPU is available!\")\n",
    "else:\n",
    "\tprint(\"GPU is not available.\")\n",
    "\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "\tprint(\"mps is available!\")\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ccb8fd0b68288898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:07:34.139816Z",
     "start_time": "2024-12-01T00:07:34.117141Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# model_id = \"roberta-base\"\n",
    "# dataset_id = \"ag_news\"\n",
    "# access_token = \"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\"\n",
    "# login(access_token)\n",
    "config_path = \"config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56e4814721e2f716",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:07:36.089313Z",
     "start_time": "2024-12-01T00:07:36.080300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open(config_path, \"r\") as file:\n",
    "\tconfig = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e1ce4bd3632b3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:07:39.658877Z",
     "start_time": "2024-12-01T00:07:38.563658Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/train_data.json\", \"r\") as f:\n",
    "\ttrain_dataset = json.load(f)\n",
    "\n",
    "with open(\"data/val_data.json\", \"r\") as f:\n",
    "\tval_dataset = json.load(f)\n",
    "\n",
    "with open(\"data/data.json\", \"r\") as f:\n",
    "\ttest_dataset = json.load(f)\n",
    "\n",
    "model_id = \"roberta-base\"\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "train_dataset = HierarchicalInterviewDataset(train_dataset)\n",
    "val_dataset = HierarchicalInterviewDataset(val_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"train\"][\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"train\"][\"batch_size\"], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f409231df09a62b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T08:48:58.421869Z",
     "start_time": "2024-11-27T08:48:58.199943Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# batch size = 8, learning rate = 0.00005\n",
    "device = torch.device(\"mps\")\n",
    "model = HierarchicalInterviewScorer().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"train\"][\"learning_rate\"])\n",
    "\n",
    "trainer = Trainer(\n",
    "\tmodel=model,\n",
    "\ttrain_loader=train_loader,\n",
    "\tval_loader=val_loader,\n",
    "\toptimizer=optimizer,\n",
    "\tdevice=device,\n",
    "\tmax_epochs=config[\"train\"][\"max_epochs\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ae640a178c454d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:05:11.358250Z",
     "start_time": "2024-11-27T08:48:59.853027Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [18:01<00:00, 77.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 11.256038648741585\n",
      "Validation Loss: 3.0221305787563324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [17:48<00:00, 76.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 2.926783915076937\n",
      "Validation Loss: 0.9018076881766319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [18:20<00:00, 78.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 1.300575899226325\n",
      "Validation Loss: 0.4693821407854557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [18:01<00:00, 77.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.7928835579327175\n",
      "Validation Loss: 0.5422789976000786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [18:31<00:00, 79.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.7598428534609931\n",
      "Validation Loss: 0.6026128903031349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [18:10<00:00, 77.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.8398936901773725\n",
      "Validation Loss: 0.5461450591683388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [20:23<00:00, 87.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.7713482486350196\n",
      "Validation Loss: 0.5558461546897888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [19:33<00:00, 83.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.735266421522413\n",
      "Validation Loss: 0.5691542252898216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [20:05<00:00, 86.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.7613536406840596\n",
      "Validation Loss: 0.5544909164309502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [20:00<00:00, 85.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.7685567332165582\n",
      "Validation Loss: 0.5522757992148399\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77654f4e7824a1c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T02:20:53.358080Z",
     "start_time": "2024-11-28T02:20:52.266317Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## change learning rate\n",
    "# batch size = 8, learning rate = 0.0001\n",
    "model2 = HierarchicalInterviewScorer().to(device)\n",
    "optimizer2 = torch.optim.AdamW(model2.parameters(), lr=0.0001)\n",
    "\n",
    "trainer2 = Trainer(\n",
    "\tmodel=model2,\n",
    "\ttrain_loader=train_loader,\n",
    "\tval_loader=val_loader,\n",
    "\toptimizer=optimizer2,\n",
    "\tdevice=device,\n",
    "\tmax_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86715e05426ebe7e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-28T02:21:00.107901Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [13:28<00:00, 57.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 7.280383178165981\n",
      "Validation Loss: 0.6019460968673229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [14:03<00:00, 60.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 0.8620352447032928\n",
      "Validation Loss: 0.818753257393837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [14:49<00:00, 63.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.8091958654778344\n",
      "Validation Loss: 0.7793813869357109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [14:24<00:00, 61.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.8575666717120579\n",
      "Validation Loss: 0.4757259637117386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [12:45<00:00, 54.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.7370774149894714\n",
      "Validation Loss: 0.7948058545589447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [13:47<00:00, 59.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.7123052967446191\n",
      "Validation Loss: 0.5838576927781105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [13:09<00:00, 56.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.7781385098184858\n",
      "Validation Loss: 0.6732175350189209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [13:24<00:00, 57.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.7481114608900887\n",
      "Validation Loss: 0.6865265369415283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [12:50<00:00, 55.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.7407018308128629\n",
      "Validation Loss: 0.5371251404285431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [12:38<00:00, 54.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6881696986300605\n",
      "Validation Loss: 0.9352904260158539\n"
     ]
    }
   ],
   "source": [
    "trainer2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a7acffc-9728-4d03-a076-837b8373730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# change batch size\n",
    "# batch size = 16, learning rate = 0.00005\n",
    "\n",
    "train_loader3 = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader3 = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "model3 = HierarchicalInterviewScorer().to(device)\n",
    "optimizer3 = torch.optim.AdamW(model3.parameters(), lr=config[\"train\"][\"learning_rate\"])\n",
    "\n",
    "trainer3 = Trainer(\n",
    "\tmodel=model3,\n",
    "\ttrain_loader=train_loader3,\n",
    "\tval_loader=val_loader3,\n",
    "\toptimizer=optimizer3,\n",
    "\tdevice=device,\n",
    "\tmax_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00da733f-7f08-4f8c-aabd-2d92076b374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [14:17<00:00, 122.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 14.726871081760951\n",
      "Validation Loss: 6.015277862548828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [13:22<00:00, 114.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 5.209017413003104\n",
      "Validation Loss: 2.175188183784485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [15:33<00:00, 133.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 2.441492932183402\n",
      "Validation Loss: 0.9421564638614655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [15:04<00:00, 129.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 1.3955279758998327\n",
      "Validation Loss: 0.5606627613306046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [13:37<00:00, 116.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 1.0461487855230058\n",
      "Validation Loss: 0.49089762568473816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [14:12<00:00, 121.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.9281942844390869\n",
      "Validation Loss: 0.5725791156291962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [14:41<00:00, 125.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.7227990627288818\n",
      "Validation Loss: 0.6229684948921204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [16:02<00:00, 137.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.7800418479101998\n",
      "Validation Loss: 0.6710667908191681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [17:03<00:00, 146.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.9306215388434274\n",
      "Validation Loss: 0.5863363146781921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [16:39<00:00, 142.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.8162517121859959\n",
      "Validation Loss: 0.524939626455307\n"
     ]
    }
   ],
   "source": [
    "trainer3.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6020c9f1-39cf-4916-97f7-5bd4271a88f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# change batch size and learning rate\n",
    "# batech size = 16, learning rate = 0.0001\n",
    "\n",
    "train_loader4 = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader4 = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "model4 = HierarchicalInterviewScorer().to(device)\n",
    "optimizer4 = torch.optim.AdamW(model4.parameters(), lr=0.0001)\n",
    "\n",
    "trainer4 = Trainer(\n",
    "\tmodel=model4,\n",
    "\ttrain_loader=train_loader4,\n",
    "\tval_loader=val_loader4,\n",
    "\toptimizer=optimizer4,\n",
    "\tdevice=device,\n",
    "\tmax_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "156376f5-a85a-4996-8525-e820a652d12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [13:56<00:00, 119.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 13.135695729936872\n",
      "Validation Loss: 3.123348116874695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [15:26<00:00, 132.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 2.733240144593375\n",
      "Validation Loss: 0.6632661074399948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [13:58<00:00, 119.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 1.0827087759971619\n",
      "Validation Loss: 0.5789893269538879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [13:54<00:00, 119.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.8255138567515782\n",
      "Validation Loss: 0.923639714717865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [14:15<00:00, 122.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.8850361364228385\n",
      "Validation Loss: 0.685541957616806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [13:38<00:00, 116.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.8453756741115025\n",
      "Validation Loss: 0.6051390767097473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [15:28<00:00, 132.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.7747819593974522\n",
      "Validation Loss: 0.6102563440799713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [16:45<00:00, 143.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.8314063208443778\n",
      "Validation Loss: 0.61602982878685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [14:36<00:00, 125.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.7762542452130999\n",
      "Validation Loss: 0.6420570015907288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [13:21<00:00, 114.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.7817148438521794\n",
      "Validation Loss: 0.6488332450389862\n"
     ]
    }
   ],
   "source": [
    "trainer4.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f42bf97-4f02-4412-a3b2-4c6c623d57e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# pretrained model \n",
    "model5 = HierarchicalInterviewScorer().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4327c19a1e0f155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:07:51.465222Z",
     "start_time": "2024-12-01T00:07:51.333600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = HierarchicalInterviewDataset(test_dataset)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"train\"][\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dacb5c1174224f2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T00:41:29.267671Z",
     "start_time": "2024-11-28T00:41:21.889546Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./hierarchical_interview_scorer.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./hierarchical_interview_scorer.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "352eaed8-ef01-4dad-89f5-22b582bdf30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./hierarchical_interview_scorer2.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./hierarchical_interview_scorer2.pth\"\n",
    "torch.save(model2.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11c27e92-cbdc-4574-b578-93f0d9b6eca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./hierarchical_interview_scorer3.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./hierarchical_interview_scorer3.pth\"\n",
    "torch.save(model3.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7723ef6-5703-4db8-8aeb-a6397cf77044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./hierarchical_interview_scorer4.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./hierarchical_interview_scorer4.pth\"\n",
    "torch.save(model4.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebd41307-da3b-4c9f-8d95-ba50abb389a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./hierarchical_interview_scorer5.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./hierarchical_interview_scorer5.pth\"\n",
    "torch.save(model5.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c32a7a12a2d3aabc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:07:58.761386Z",
     "start_time": "2024-12-01T00:07:58.690798Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved to ./tokenizer\n"
     ]
    }
   ],
   "source": [
    "tokenizer_save_path = \"./tokenizer\"\n",
    "tokenizer.save_pretrained(tokenizer_save_path)\n",
    "print(f\"Tokenizer saved to {tokenizer_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e0e38bc1461f8ec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:09:42.846488Z",
     "start_time": "2024-12-01T00:09:38.733177Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/46/r2xvz0y951d70p_0ghbtyd_c0000gn/T/ipykernel_52017/65858776.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizerFast\n",
    "from model import HierarchicalInterviewScorer \n",
    "\n",
    "model_save_path = \"./hierarchical_interview_scorer.pth\"\n",
    "tokenizer_save_path = \"./tokenizer\"\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_save_path)\n",
    "\n",
    "model = HierarchicalInterviewScorer()\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae71257468dcfd2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:14:06.983366Z",
     "start_time": "2024-12-01T00:09:47.039571Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_true_scores = []\n",
    "all_predicted_scores = []\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\tfor dialogue_turns, labels in test_loader:\n",
    "\t\tdialogue_turns = {k: v.to(device) for k, v in dialogue_turns.items()}\n",
    "\t\tlabels = labels.to(device)\n",
    "\n",
    "\t\tpredictions = model(dialogue_turns)\n",
    "\n",
    "\t\tall_true_scores.extend(labels.cpu().numpy())\n",
    "\t\tall_predicted_scores.extend(predictions.cpu().numpy())\n",
    "\n",
    "all_true_scores_tensor = torch.tensor(all_true_scores)\n",
    "all_predicted_scores_tensor = torch.tensor(all_predicted_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "af41342adb1ddeee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:14:16.387228Z",
     "start_time": "2024-12-01T00:14:16.371467Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.5354816913604736\n"
     ]
    }
   ],
   "source": [
    "mse_loss = torch.nn.MSELoss()\n",
    "mse = mse_loss(all_predicted_scores_tensor, all_true_scores_tensor)\n",
    "print(f\"Mean Squared Error: {mse.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "708a0aeebde5bda8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:14:27.508797Z",
     "start_time": "2024-12-01T00:14:27.494461Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(predicted_scores, actual_scores, tolerance=1.0):\n",
    "\tassert predicted_scores.shape == actual_scores.shape, \"Shapes of predictions and actual scores must match.\"\n",
    "\tdifferences = torch.abs(predicted_scores - actual_scores)\n",
    "\tcorrect_predictions = (differences <= tolerance).float() \n",
    "\taccuracy = correct_predictions.mean().item()\n",
    "\n",
    "\treturn accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bb3611573d2f02a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:14:42.224468Z",
     "start_time": "2024-12-01T00:14:41.936682Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.61%\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(all_predicted_scores_tensor, all_true_scores_tensor, tolerance =1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b99dd00-37d7-408a-b535-38ceda2f25aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/46/r2xvz0y951d70p_0ghbtyd_c0000gn/T/ipykernel_52017/1793219003.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model2.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizerFast\n",
    "from model import HierarchicalInterviewScorer \n",
    "\n",
    "model_save_path = \"./hierarchical_interview_scorer2.pth\"\n",
    "tokenizer_save_path = \"./tokenizer\"\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_save_path)\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "model2 = HierarchicalInterviewScorer().to(device)\n",
    "model2.load_state_dict(torch.load(model_save_path))\n",
    "model2.eval()\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8599240e-7788-41e0-956b-c5d918589f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_scores = []\n",
    "all_predicted_scores = []\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\tfor dialogue_turns, labels in test_loader:\n",
    "\t\tdialogue_turns = {k: v.to(device) for k, v in dialogue_turns.items()}\n",
    "\t\tlabels = labels.to(device)\n",
    "\n",
    "\t\tpredictions = model2(dialogue_turns)\n",
    "\n",
    "\t\tall_true_scores.extend(labels.cpu().numpy())\n",
    "\t\tall_predicted_scores.extend(predictions.cpu().numpy())\n",
    "\n",
    "all_true_scores_tensor = torch.tensor(all_true_scores)\n",
    "all_predicted_scores_tensor = torch.tensor(all_predicted_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5737ce36-b5de-416f-8ccd-cc93a7213d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for model 2: 0.8754754662513733\n"
     ]
    }
   ],
   "source": [
    "mse_loss = torch.nn.MSELoss()\n",
    "mse = mse_loss(all_predicted_scores_tensor, all_true_scores_tensor)\n",
    "print(f\"Mean Squared Error for model 2: {mse.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49fd57d135b9eff1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:25:38.216541Z",
     "start_time": "2024-12-01T00:25:35.296173Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model 2: 72.71%\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(all_predicted_scores_tensor, all_true_scores_tensor, tolerance =1)\n",
    "\n",
    "print(f\"Accuracy for model 2: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e69c4b6-09d5-4589-82cb-9eecb63c1bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T00:31:00.610133Z",
     "start_time": "2024-12-01T00:26:59.940051Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/46/r2xvz0y951d70p_0ghbtyd_c0000gn/T/ipykernel_52017/3413050725.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model3.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./hierarchical_interview_scorer3.pth\"\n",
    "tokenizer_save_path = \"./tokenizer\"\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_save_path)\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "model3 = HierarchicalInterviewScorer().to(device)\n",
    "model3.load_state_dict(torch.load(model_save_path))\n",
    "model3.eval()\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a46b3c7e-a2c6-4eb1-a8f3-415339464eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_scores = []\n",
    "all_predicted_scores = []\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\tfor dialogue_turns, labels in test_loader:\n",
    "\t\tdialogue_turns = {k: v.to(device) for k, v in dialogue_turns.items()}\n",
    "\t\tlabels = labels.to(device)\n",
    "\n",
    "\t\tpredictions = model3(dialogue_turns)\n",
    "\n",
    "\t\tall_true_scores.extend(labels.cpu().numpy())\n",
    "\t\tall_predicted_scores.extend(predictions.cpu().numpy())\n",
    "\n",
    "all_true_scores_tensor = torch.tensor(all_true_scores)\n",
    "all_predicted_scores_tensor = torch.tensor(all_predicted_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f977284e-dbd0-4cb1-b436-fc624cf302cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for model 3: 0.49207308888435364\n"
     ]
    }
   ],
   "source": [
    "mse_loss = torch.nn.MSELoss()\n",
    "mse = mse_loss(all_predicted_scores_tensor, all_true_scores_tensor)\n",
    "print(f\"Mean Squared Error for model 3: {mse.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96c44230-40ea-4d94-aade-38bad9bff33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model 3: 83.82%\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(all_predicted_scores_tensor, all_true_scores_tensor, tolerance =1)\n",
    "\n",
    "print(f\"Accuracy for model 3: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43591097-d867-4ce0-9809-70ab4e528ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/46/r2xvz0y951d70p_0ghbtyd_c0000gn/T/ipykernel_52017/779313121.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model4.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n",
      "Mean Squared Error for model 4: 0.6074193120002747\n",
      "Accuracy for model 4: 80.43%\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./hierarchical_interview_scorer4.pth\"\n",
    "tokenizer_save_path = \"./tokenizer\"\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_save_path)\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "model4 = HierarchicalInterviewScorer().to(device)\n",
    "model4.load_state_dict(torch.load(model_save_path))\n",
    "model4.eval()\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")\n",
    "\n",
    "all_true_scores = []\n",
    "all_predicted_scores = []\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\tfor dialogue_turns, labels in test_loader:\n",
    "\t\tdialogue_turns = {k: v.to(device) for k, v in dialogue_turns.items()}\n",
    "\t\tlabels = labels.to(device)\n",
    "\n",
    "\t\tpredictions = model4(dialogue_turns)\n",
    "\n",
    "\t\tall_true_scores.extend(labels.cpu().numpy())\n",
    "\t\tall_predicted_scores.extend(predictions.cpu().numpy())\n",
    "\n",
    "all_true_scores_tensor = torch.tensor(all_true_scores)\n",
    "all_predicted_scores_tensor = torch.tensor(all_predicted_scores)\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "mse = mse_loss(all_predicted_scores_tensor, all_true_scores_tensor)\n",
    "print(f\"Mean Squared Error for model 4: {mse.item()}\")\n",
    "\n",
    "accuracy = calculate_accuracy(all_predicted_scores_tensor, all_true_scores_tensor, tolerance =1)\n",
    "\n",
    "print(f\"Accuracy for model 4: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94975d34-c478-43b3-9d9a-f013aa987e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/46/r2xvz0y951d70p_0ghbtyd_c0000gn/T/ipykernel_52017/1876924268.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model5.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n",
      "Mean Squared Error for model 5: 23.521717071533203\n",
      "Accuracy for model 5: 0.00%\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./hierarchical_interview_scorer5.pth\"\n",
    "tokenizer_save_path = \"./tokenizer\"\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_save_path)\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "model5 = HierarchicalInterviewScorer().to(device)\n",
    "model5.load_state_dict(torch.load(model_save_path))\n",
    "model5.eval()\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")\n",
    "\n",
    "all_true_scores = []\n",
    "all_predicted_scores = []\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\tfor dialogue_turns, labels in test_loader:\n",
    "\t\tdialogue_turns = {k: v.to(device) for k, v in dialogue_turns.items()}\n",
    "\t\tlabels = labels.to(device)\n",
    "\n",
    "\t\tpredictions = model5(dialogue_turns)\n",
    "\n",
    "\t\tall_true_scores.extend(labels.cpu().numpy())\n",
    "\t\tall_predicted_scores.extend(predictions.cpu().numpy())\n",
    "\n",
    "all_true_scores_tensor = torch.tensor(all_true_scores)\n",
    "all_predicted_scores_tensor = torch.tensor(all_predicted_scores)\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "mse = mse_loss(all_predicted_scores_tensor, all_true_scores_tensor)\n",
    "print(f\"Mean Squared Error for model 5: {mse.item()}\")\n",
    "\n",
    "accuracy = calculate_accuracy(all_predicted_scores_tensor, all_true_scores_tensor, tolerance =1)\n",
    "\n",
    "print(f\"Accuracy for model 5: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8c151c5-322a-4c29-9a30-4960252eda57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency per batch: 1.1654 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=lambda batch: {\n",
    "        \"input_ids\": torch.stack([item[0][\"input_ids\"] for item in batch]),\n",
    "        \"attention_mask\": torch.stack([item[0][\"attention_mask\"] for item in batch]),\n",
    "        \"labels\": torch.stack([item[1] for item in batch])\n",
    "    }\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "model.to(device)\n",
    "\n",
    "latencies = []\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    inputs = {\"input_ids\": batch[\"input_ids\"], \"attention_mask\": batch[\"attention_mask\"]}\n",
    "    labels = batch[\"labels\"]\n",
    "\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    labels = labels.to(device)\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    latencies.append(elapsed_time)\n",
    "    break\n",
    "\n",
    "average_latency = sum(latencies) / len(latencies)\n",
    "print(f\"Latency per batch: {average_latency:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "214e19aa-8711-446c-bb6d-afa3c5b3b3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Throughput: 8.55 samples/second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=lambda batch: {\n",
    "        \"input_ids\": torch.stack([item[0][\"input_ids\"] for item in batch]),\n",
    "        \"attention_mask\": torch.stack([item[0][\"attention_mask\"] for item in batch]),\n",
    "        \"labels\": torch.stack([item[1] for item in batch])\n",
    "    }\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "model.to(device)\n",
    "\n",
    "total_samples = 0\n",
    "total_time = 0\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    inputs = {\"input_ids\": batch[\"input_ids\"], \"attention_mask\": batch[\"attention_mask\"]}\n",
    "    labels = batch[\"labels\"]\n",
    "\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    labels = labels.to(device)\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    total_samples += batch_size\n",
    "    total_time += elapsed_time\n",
    "throughput = total_samples / total_time\n",
    "print(f\"Throughput: {throughput:.2f} samples/second\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c07fdb5-e198-48f1-85b9-753aa0dc194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 135871235\n",
      "Trainable Parameters: 135871235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "def display_model_parameters(model):\n",
    "    print(f\"{'Layer':50} {'Size':30} {'Requires Grad':15} {'Num Params':10}\")\n",
    "    print(\"=\"*100)\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name:50} {str(list(param.size())):30} {str(param.requires_grad):15} {param.numel():10}\")\n",
    "\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(f\"Trainable Parameters: {trainable_params}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c04173-5df8-46b4-9863-3e82c8de3129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
